substitutions:
  _REGION: us-central1
  _MODEL_NAME: casas-model
  _PIPELINE_PACKAGE: mlops-pipelines==0.1.0

steps:
  # =====================================================
  # 1) Build da imagem de treino
  # =====================================================
  - id: build-training-image
    name: gcr.io/cloud-builders/docker
    args:
      - build
      - -t
      - ${_REGION}-docker.pkg.dev/$PROJECT_ID/mlops/${_MODEL_NAME}:${SHORT_SHA}
      - .

  # =====================================================
  # 2) Push da imagem
  # =====================================================
  - id: push-training-image
    name: gcr.io/cloud-builders/docker
    args:
      - push
      - ${_REGION}-docker.pkg.dev/$PROJECT_ID/mlops/${_MODEL_NAME}:${SHORT_SHA}
    waitFor: ["build-training-image"]

# =====================================================
# 3) Compile pipeline + submit no Vertex
# =====================================================
  - id: compile-and-submit-pipeline
    name: python:3.11
    entrypoint: bash
    args:
      - -c
      - |
        set -e

        # Instala tudo que esse step precisa
        python -m pip install --upgrade pip
        python -m pip install \
          --extra-index-url https://us-central1-python.pkg.dev/$PROJECT_ID/mlops-python/simple/ \
          mlops-pipelines==0.1.0 \
          google-cloud-aiplatform

        # Compila pipeline
        python - <<EOF
        from kfp.compiler import Compiler
        from mlops_pipelines.pipelines.training import training_pipeline

        Compiler().compile(
            pipeline_func=training_pipeline,
            package_path="pipeline.json",
        )
        EOF

        # Submete no Vertex
        python - <<EOF
        from google.cloud import aiplatform

        aiplatform.init(
            project="${PROJECT_ID}",
            location="${_REGION}",
        )

        job = aiplatform.PipelineJob(
            display_name="train-${_MODEL_NAME}-${SHORT_SHA}",
            template_path="pipeline.json",
            parameter_values={
                "project_id": "${PROJECT_ID}",
                "region": "${_REGION}",
                "model_name": "${_MODEL_NAME}",
                "image_uri": "${_IMAGE_URI}",
                "dataset_uri": "bq://${PROJECT_ID}.mlops_trial.casas_rw",
                "run_id": "${SHORT_SHA}",
                "environment": "dev",
            },
        )

        job.run(sync=False)

        print("")
        print("=================================================")
        print("ðŸš€ Pipeline submetida com sucesso ao Vertex AI")
        print("-------------------------------------------------")
        print(f"ðŸ“¦ Projeto:        {PROJECT_ID}")
        print(f"ðŸŒ RegiÃ£o:         {REGION}")
        print(f"ðŸ§  Modelo:         {MODEL_NAME}")
        print(f"ðŸ–¼ï¸  Image URI:     {IMAGE_URI}")
        print(f"ðŸ“Š Dataset URI:   {DATASET_URI}")
        print(f"ðŸ” Run ID:         {RUN_ID}")
        print(f"ðŸ·ï¸  Ambiente:      {ENVIRONMENT}")
        print("-------------------------------------------------")
        print(f"ðŸ”— Vertex UI:")
        print(f"https://console.cloud.google.com/vertex-ai/locations/{REGION}/pipelines/runs/{job.resource_name.split('/')[-1]}?project={PROJECT_ID}")
        print("-------------------------------------------------")
        print("â„¹ï¸  A execuÃ§Ã£o continuarÃ¡ de forma assÃ­ncrona no Vertex AI.")
        print("â„¹ï¸  O Cloud Build foi finalizado com sucesso.")
        print("=================================================")
        print("")
        EOF

options:
  logging: CLOUD_LOGGING_ONLY
