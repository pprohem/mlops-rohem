substitutions:
  _REGION: us-central1
  _MODEL_NAME: casas-model
  _PIPELINE_PACKAGE: mlops-pipelines==0.2.3
  _IMAGE_URI: us-central1-docker.pkg.dev/mlops-rohem/mlops/${_MODEL_NAME}:${SHORT_SHA}

steps:
  # =====================================================
  # 1) Build da imagem de treino
  # =====================================================
  - id: build-training-image
    name: gcr.io/cloud-builders/docker
    args:
      - build
      - -t
      - ${_IMAGE_URI}
      - .

  # =====================================================
  # 2) Push da imagem
  # =====================================================
  - id: push-training-image
    name: gcr.io/cloud-builders/docker
    args:
      - push
      - ${_IMAGE_URI}
    waitFor: ["build-training-image"]

  # =====================================================
  # 3) Compile + Submit pipeline (FIRE-AND-FORGET)
  # =====================================================
  - id: submit-vertex-pipeline
    name: python:3.11
    entrypoint: bash
    waitFor: ["push-training-image"]
    args:
      - -c
      - |
        set -e

        echo "ðŸ”§ Instalando dependÃªncias mÃ­nimas..."
        python -m pip install --upgrade pip > /dev/null

        python -m pip install \
          --quiet \
          --extra-index-url https://us-central1-python.pkg.dev/mlops-rohem/mlops-python/simple/ \
          ${_PIPELINE_PACKAGE} \
          google-cloud-aiplatform \
          kfp

        echo "ðŸ“¦ Compilando pipeline..."
        python - <<'EOF'
        from kfp.compiler import Compiler
        from mlops_pipelines.pipelines.training import training_pipeline

        Compiler().compile(
            pipeline_func=training_pipeline,
            package_path="pipeline.json",
        )
        EOF

        echo "ðŸš€ Submetendo pipeline ao Vertex AI (async)..."
        python - <<'EOF'
        from google.cloud import aiplatform

        PROJECT_ID = "${PROJECT_ID}"
        REGION = "${_REGION}"
        MODEL_NAME = "${_MODEL_NAME}"
        IMAGE_URI = "${_IMAGE_URI}"
        DATASET_URI = f"bq://{PROJECT_ID}.mlops_trial.casas_rw"
        RUN_ID = "${SHORT_SHA}"
        ENVIRONMENT = "dev"

        PIPELINE_DISPLAY_NAME = f"train-{MODEL_NAME}-{RUN_ID}"

        aiplatform.init(
            project=PROJECT_ID,
            location=REGION,
        )

        job = aiplatform.PipelineJob(
            display_name=PIPELINE_DISPLAY_NAME,
            template_path="pipeline.json",
            parameter_values={
                "project_id": PROJECT_ID,
                "region": REGION,
                "model_name": MODEL_NAME,
                "image_uri": IMAGE_URI,
                "dataset_uri": DATASET_URI,
                "run_id": RUN_ID,
                "environment": ENVIRONMENT,
            },
        )

        # ðŸ”¥ FIRE-AND-FORGET REAL
        job.run(sync=False)

        print("")
        print("=================================================")
        print("ðŸš€ Pipeline submetida com sucesso ao Vertex AI")
        print("-------------------------------------------------")
        print(f"ðŸ§  Modelo:     {MODEL_NAME}")
        print(f"ðŸ” Run ID:     {RUN_ID}")
        print(f"ðŸ–¼ï¸ Image URI: {IMAGE_URI}")
        print(f"ðŸ“Š Dataset:   {DATASET_URI}")
        print("-------------------------------------------------")
        print("ðŸ”— Vertex Pipelines:")
        print(
            f"https://console.cloud.google.com/vertex-ai/locations/"
            f"{REGION}/pipelines?project={PROJECT_ID}"
        )
        print("â„¹ï¸ ExecuÃ§Ã£o assÃ­ncrona. Cloud Build encerrando.")
        print("=================================================")
        EOF

options:
  logging: CLOUD_LOGGING_ONLY
